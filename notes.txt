Allow loading .obj geometry onto a body.
---
How would we generalize this to have multiple solving passes?
* It seems like we are effectively setting up multiple solve tags.
  Maybe each solver has a solve tag associated with it.  Each value
  can be tagged with any of the solve tags.
  * Potentially a value could have a number of tags and a solver could
    have a number of tags and the values that get solved are the ones
    where there are matching tags.
  * Potentially an error could also have a tag, maybe a different set of tags.
* We may want to have local solvers.
  * For example, if we are trying to make rays point in the right direction,
    we could have a local solver for each ray which makes the ray point
    in the right direction relative to the camera, and then we have a
    solver for each camera which makes the camera translate and rotate
    to match rays in 3D, then we have another solver which tries to
    make 3D points which match the rays. The camera solver and the point
    solver could be combined into a larger solver which solves both.
---
Instead of having different kinds of errors, we could just be able to put
an error on various values.

Distance {
  start_marker: "marker1"
  end_marker: "marker2"
  value: 2.3 {
    error: 5 {
      desired_value: 7.3
      weight: 1
    }
  }
}

Body {
  translation: [] {
    x: 3 {
      error: 1 {
        desired_value: 2
        weight: 1
      }
    }
  }
---
It might be nice to treat a handle on a marker as setting temporary
desired values and solving rather than setting the values directly.
* This would allow for us moving markers which are driven by expressions.
* It would end up solving variables and moving the marker to the closest
  position that was supported by the variables.

One thing that seems missing is the ability to specify an expression for
the position of a marker which depends on the marker position's components.
We'd want to have an expression like: [x*scale, y*scale, z*scale].  When
setting the marker position, we could calculate the component values.
We would try to calculate scale.

For this to work, it seems like we should make a distinction between linear
and non-linear solving.  If the expression that drives a marker position
is linear, then we can invert the expression and calculate the position
directly.  Maybe initially, we would only support linear expressions, and
add support for non-linear expressions later.
---
I'd like to be able to support 3D curves.  It would be possible to draw
a curve by using line segments.

LineStrip {
  Vertex {
    x: 0
    y: 0
    z: 0
  }
  Vertex {
    x: 1
    y: 1
    z: 1
  }
}


LineStrip {
  ForEach {
    variable: "i"
    values: {
      0
      1
    }
    Vertex {
      x : i
      y : i
      z : i
    }
  }
}


LineStrip {
  ForEach {
    variable: "i"
    values {
      0
      1
    }
    Vertex {
      x : 0 {
        expression: "xCurve(i)"
      }
      y : 0 {
        expression: "yCurve(i)"
      }
      z : 0 {
        expression: "zCurve(i)"
      }
    }
  }
}


BSpline3D {
  name: "bspline"
  Piece {
    knot: 0
    control_point: {
      x: 0
      y: 0
      z: 0
    }
  }
  Piece {
    knot: 1
    control_point {
      x: 1
      y: 1
      z: 1
    }
  }
}

BSplineMarker {
  name: "marker3"
  bspline: "bspline"
  parameter: 0
}

Marker {
  name: "marker3"
  position: {
    expression: "bspline(t)"
    t: 5
  }
}


Function {
  name: "BSpline"
  Child {
    name: "Piece"
    Param {
      name: "knot"
      type: Real
    }
    Param {
      name: "control_point"
      type: Point
    }
  }
  Define {
    name: "pieces"
    value: Children(type=Piece)
  }
  LineStrip {
    ForEach {
      variable: "i"
      values: Range {
        start: 0
        count: n_segments
      }
      Define {
        name: "fraction"
        value: "i/n_segments"
      }
      Define {
        name: "x"
        value: "lerp(first_knot, last_knot, fraction)"
      }
    }
  }
}
---
When we have live values, it makes sense to have something that shows the
current value, but inside a function, there's no such thing as the live
value.
* Perhaps if we think of partial evaluation it could work.  The live value
  of a value inside a function is the partial evaluation.  So we can have

Function {
  name: "f"
  Param {
    name: "x"
    type: Real
  }
  Result: x*2 + 15 {
    expression: "x*2 + (5*3)"
  }
}
---
One thing that could be neat is being able to double-click on a mesh, and
have that put us into a mode where we can select faces and vertices.
---
I'd like to be able to take a box and have a distance error between certain
vertices and certain global positions.

* Select a vertex position.
* Add a marker to the vertex position.
* Add a distance error between that marker and the other one.

It seems like markers may just become names for things.  Maybe instead of
markers we just have points, and then we can give those points names.  We
could then give vertex positions names as well, or give body translations
names.

Seems like the main problem we're trying to solve is how to reference things.
In a lot of cases, we may not care about giving something a name as long
as we have a way to reference it.

Cutting is similar to marking. Maybe we could do something like marking
a vertex, and then we go somewhere else and have a "Set to marked" operation.

* Right-click on a vertex in the tree, choose "Mark".
* Right-click on a distance error start, then choose "Set to Mark".

The relationship between "markers" and "marks" is interesting.  We could
think of a marker as a visual mark.

* Select a mesh position
* Right-click "Add Mark"
* Select another mesh position
* Right-click "Add Mark"
* Marks Menu: "Add Distance Error Between Marks"

---
If you select the position of a mesh in the tree, the mesh should become
unselected in the scene.
---
If you select the "positions" child of a Mesh, it should make it where you
can select individual vertices.

We could create a sphere for each vertex, so that we have somthing to click on.
The set of spheres seems similar to a manipulator.

The ManipulatorType is in Scene currently, but the Scene isn't going to know
about a "points" manipulator.  It seems like we may need another enum for
this higher-level kind of manipulator.

It may be that separating the manipulator type from the item isn't right.


We use properManipulatorForSceneObject() in
  properManipulatorForSelectedObject()
    MainWindowController::Impl::handleSceneChanging().
      forEachSolveFlagAffectingHandle()
  attachProperDraggerToSelectedObject()

So the separation is somewhat necessary:
  * For example, we may have a body selected, and we are using the translate
    manipulator.
  * So we're interested in the body rotation, even though what is selected
    is a body.
  * Likewise, we may have a body.rotation.x selected, and we are manipulating
    the whole body.rotation.
  * So this gets back to needing a generic way of describing things in the
    scene.  If we had a way of describing body.rotation, then we could just
    request that a manipulator be attached to Body.rotation, even though what
    is selected in the tree is Body.rotation.x or Body
---
We have two ways of describing things in the scene:
* TreeItemDescription
* SceneElement
